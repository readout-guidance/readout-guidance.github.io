<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <meta content="Readout Guidance: Learning Control from Diffusion Features" property="og:title">
  <meta content="Readout Guidance: Learning Control from Diffusion Features" property="twitter:title">
  <meta property="og:type" content="website">
  
  <link rel="icon" type="image/png" href="assets/icon.png" />
  <title>Readout Guidance: Learning Control from Diffusion Features</title>
  <meta name="description" content="Readout Guidance is a method for controlling text-to-image diffusion models with learned signals.">
  <meta name="keywords" content="readout guidance, self guidance, diffusion hyperfeatures, diffusion features, classifier guidance, guidance, diffusion models">

  <meta content="Readout Guidance: Learning Control from Diffusion Features" property="twitter:title" />
  <meta content="Readout Guidance: Learning Control from Diffusion Features" property="twitter:description" />

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-3LCW3JHW2E"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-3LCW3JHW2E');
  </script>

  <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
  <!-- popper used for tooltips -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js"></script>
  <!-- bootstrap styling used for carousel -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="./static/css/custom.css">
  <link rel="stylesheet" href="./static/css/fonts.css">

  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/interactions.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body" style="padding: 3rem 1.5rem 0.5rem 1.5rem;">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">Readout Guidance: Learning Control<br/> from Diffusion Features</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://people.eecs.berkeley.edu/~graceluo" target="_blank">Grace Luo</a><sup>1, 2</sup>
            </span>
            <span class="author-block">
              <a href="http://people.eecs.berkeley.edu/~trevor" target="_blank">Trevor Darrell</a><sup>2</sup>
            </span>
            <span class="author-block">
              <a href="https://oliverwang.nfshost.com" target="_blank">Oliver Wang</a><sup>1</sup>
            </span>
            <span class="author-block">
              <a href="https://www.danbgoldman.com" target="_blank">Dan B Goldman</a><sup>1</sup>
            </span>
            <span class="author-block">
              <a href="https://holynski.org" target="_blank">Aleksander Holynski</a><sup>1, 2</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Google Research</span>
            <span class="author-block"><sup>2</sup>UC Berkeley</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="" target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="#demo" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <img src="assets/hand.svg" />
                  </span>
                  <span>Gallery</span>
                </a>
              </span>
              <span class="link-block">
                <a href="" class="external-link button is-normal is-rounded is-dark" disabled>
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (Coming Soon)</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Abstract -->
<section style="padding: 1.5rem 1.5rem 3rem 1.5rem;" class="section">
  <div class="container is-max-desktop">
    <div class="teaser-caption caption columns is-centered has-text-centered">
      <div>
        <!-- <img src="assets/replay.png" />
        <span class="replay">Replay Video.</span> -->
        <span><b>TL;DR: </b>We train very small networks called "readout heads" to predict useful properties and guide image generation.</span>
      </div>
    </div>
    <div class="results-grid">
      <div class="results-single">
        <video id="teaser" autoplay muted playsinline loop>
          <source src="assets/teaser.m4v" type="video/mp4">
        </video>
      </div>
    </div>
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 style="margin-top: 2.5rem;" class="title is-4">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We present Readout Guidance, a method for controlling text-to-image diffusion models with learned signals. 
            Readout Guidance uses <i>readout heads</i>, lightweight networks trained to extract signals 
            from the features of a pre-trained, frozen diffusion model at every timestep. 
            These readouts can encode single-image properties, such as pose, depth, and edges; 
            or higher-order properties that relate multiple images, such as correspondence and appearance similarity. 
            Furthermore, by comparing the readout estimates to a user-defined target, and back-propagating the gradient through the readout head, 
            these estimates can be used to guide the sampling process. Compared to prior methods for conditional generation, 
            Readout Guidance requires significantly fewer added parameters and training samples, and offers a convenient and simple recipe for 
            reproducing different forms of conditional control under a single framework, with a single architecture and sampling procedure. 
            We showcase these benefits in the applications of drag-based manipulation, identity-consistent generation, and spatially aligned control.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!--/ Abstract -->

<!-- Inuition -->
<hr>
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-4 is-centered has-text-centered">Extracting Readouts</h2>
    <div class="results-grid">
      <div class="results-single">
        <video autoplay muted playsinline loop>
          <source src="assets/intuition.m4v" type="video/mp4">
        </video>
      </div>
    </div>
     <div>Given a frozen text-to-image diffusion model, we train parameter-efficient <i>readout heads</i> to interpret relevant signals, or <i>readouts</i>, from the intermediate network features. Training requires as few as 100 paired examples, since the heads bootstrap pre-trained diffusion features. During sampling, a readout head can be used at any timestep to query the model's current estimate of a particular property (for the image being generated).</div>
  </div>
</section>
<!-- Inuition -->

<!-- Approach -->
<hr>
<section class="section">
  <div class="container is-max-desktop">
      <h2 class="title is-4 is-centered has-text-centered" style="margin-bottom:0;">Readout Guidance</h2>
      <br>
      <div class="columns is-vcentered">
        <div class="column is-three-fifths">
          <img src="assets/approach.png" />
        </div>
        <div class="column is-two-fifths">
          <p style="margin-left:25px;">These readouts can also be used for controlled image generation---by guiding the readout towards some desired value. Readouts for single-image concepts, such as pose and depth, enable spatially aligned control. Readouts for relative concepts between two images, such as appearance similarity and correspondence, enable cross-image controls, such as drag-based manipulation, identity-consistent generation, or image variations.
          </p>
        </div>
    </div>
  </div>
</section>
<!-- Approach -->

<!-- Spatially Aligned Control -->
<hr>
<section id="demo" class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-4 is-centered has-text-centered">Spatially Aligned Control</h2>
    <div class="caption">We can perform pose, depth, or edge-guided generation, similar to ControlNet.</div>
    <div class="columns is-centered has-text-centered">
      <img class="info-icon" src="assets/info.svg" />
      <button type="button" class="btn btn-caption btn-sm" disabled>This application uses the&nbsp;</button>
      <button type="button" class="btn btn-caption btn-sm" data-toggle="tooltip" data-placement="bottom" title="This head is trained to produce an estimate of human pose. We use OpenPose to create our training examples." disabled>Pose Head,&nbsp;</button>
      <button type="button" class="btn btn-caption btn-sm" data-toggle="tooltip" data-placement="bottom" title="This head is trained to produce depth maps. We use MiDaS to create our training examples." disabled>Depth Head,&nbsp;</button>
      <button type="button" class="btn btn-caption btn-sm" disabled>or&nbsp;</button>
      <button type="button" class="btn btn-caption btn-sm" data-toggle="tooltip" data-placement="bottom" title="This head is trained to produce edge maps. We use the HED edge detector to create training examples." disabled>Edge Head</button>
      <button type="button" class="btn btn-caption btn-sm" disabled></button>
    </div>
    <br>
    <div class="btn-row">
      <span>input type:<br></span>
      <button type="button" onClick="setActiveButton(this)" class="btn btn-modality btn-select btn-active" btn-modality="pose" prompt-key="poseSpatial">pose</button>
      <button type="button" onClick="setActiveButton(this)" class="btn btn-modality btn-select" btn-modality="depth" prompt-key="depthSpatial">depth</button>
      <button type="button" onClick="setActiveButton(this)" class="btn btn-modality btn-select" btn-modality="edge" prompt-key="edgeSpatial">edge</button>
    </div>
    <div class="btn-row">
    <span>prompt:<br></span>
      <button type="button" onClick="setActiveButton(this)" class="btn btn-spatial btn-select btn-active" btn-spatial="1">a group of people playing with Frisbee's on the grass</button>
      <button type="button" onClick="setActiveButton(this)" class="btn btn-spatial btn-select" btn-spatial="2">two men on a tennis court shaking hands over the net</button>
    </div>
    <br>
    <div class="results-grid">
      <div class="results-single">
        <img src="assets/spatial/empty.png">
        <video class="layered-video" id="dynamic-spatial" autoplay muted playsinline loop>
          <source src="assets/spatial/pose_1.m4v" type="video/mp4">
        </video>
      </div>
    </div>
  </div>
</section>
<!-- Spatially Aligned Control -->

<!-- Drag_based Manipulation -->
<hr>
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-4 is-centered has-text-centered">Drag-Based Manipulation</h2>
    <div class="caption">
      We can enable drag-based manipulation of real and generated images.
    </div>
    <div class="columns is-centered has-text-centered">
      <img class="info-icon" src="assets/info.svg" />
      <button type="button" class="btn btn-caption btn-sm" disabled>This application uses the&nbsp;</button>
    	<button type="button" class="btn btn-caption btn-sm" data-toggle="tooltip" data-placement="bottom" title="This head is trained to enable correspondence estimation between a pair of images. We use CoTracker to create training examples." disabled>Correspondence Feature Head,&nbsp;</button>
    	<button type="button" class="btn btn-caption btn-sm" data-toggle="tooltip" data-placement="bottom" title="This head is trained contrastively to provide a metric for appearance similarity between two images. As positive examples, we use pairs of frames from a video." disabled>Appearance Similarity Head</button>
    </div>
    <br>
    <div class="title is-5">Generated Images</div>
    <div class="btn-row">
      <span>prompt:<br></span>
      <button type="button" onClick="setActiveButton(this)" class="btn btn-prompt btn-select btn-active" btn-prompt="squirrel">photo of a squirrel with a hamburger at its feet</button>
      <button type="button" onClick="setActiveButton(this)" class="btn btn-prompt btn-select" btn-prompt="bear">a bear dancing on times square</button>
      <button type="button" onClick="setActiveButton(this)" class="btn btn-prompt btn-select" btn-prompt="headshot-woman">professional headshot of a woman with the eiffel tower in the background</button>
      <button type="button" onClick="setActiveButton(this)" class="btn btn-prompt btn-select" btn-prompt="dog">photo of a beagle hovering mid-air</button>
    </div>
    <div class="btn-row">
    <span>edit:<br></span>
      <button type="button" onClick="setActiveButton(this)" class="btn btn-drag btn-select btn-active" btn-drag="1">drag 1</button>
      <button type="button" onClick="setActiveButton(this)" class="btn btn-drag btn-select" btn-drag="2">drag 2</button>
      <button type="button" onClick="setActiveButton(this)" class="btn btn-drag btn-select" btn-drag="3">drag 3</button>
    </div>
    <br>
    <div class="results-grid">
      <div class="results-pair">
        <img id="dynamic-drag" src="assets/drag_synthetic/squirrel_1.png" />
        <img id="dynamic-result" src="assets/drag_synthetic/squirrel_1.gif" />
      </div>
    </div>
    <br><br><br>
    <div class="title is-5">Real Images</div>
    <div class="btn-row">
      <span>prompt:<br></span>
      <button type="button" onClick="setActiveButton(this)" class="btn btn-prompt-real btn-select btn-active" btn-prompt-real="wolf-looking">wolf looking around</button>
      <button type="button" onClick="setActiveButton(this)" class="btn btn-prompt-real btn-select" btn-prompt-real="JH_2023-09-14-1823-02">a photo of a tiger</button>
      <button type="button" onClick="setActiveButton(this)" class="btn btn-prompt-real btn-select" btn-prompt-real="JH_2023-09-14-1825-41">a photo of a man holding a crocodile</button>
      <button type="button" onClick="setActiveButton(this)" class="btn btn-prompt-real btn-select" btn-prompt-real="JH_2023-09-14-1838-08">a photo of a rabbit</button>
      <button type="button" onClick="setActiveButton(this)" class="btn btn-prompt-real btn-select" btn-prompt-real="JH_2023-09-14-1826-07">a photo of a raccoon</button>
      <button type="button" onClick="setActiveButton(this)" class="btn btn-prompt-real btn-select" btn-prompt-real="alpine-ibex">an alpine ibex with horns</button>
    </div>
    <br>
    <div class="results-grid">
      <div class="results-pair">
        <img id="dynamic-drag-real" src="assets/drag_real/wolf-looking.png" />
        <img id="dynamic-result-real" src="assets/drag_real/wolf-looking.gif" />
      </div>
      <div style="margin-top: 10px; margin-bottom: 0px;" class="caption">
        We can do the same manipulations on real images without per-sample optimization, where we guide against features derived from inverting the real image.
      </div>
    </div>
  </div>
</section>
<!-- Drag_based Manipulation -->

<!-- Identity Consistency -->
<hr>
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-4 is-centered has-text-centered">Identity Consistency</h2>
    <div class="caption">
      We can guide a generated image to contain a specific identity, defined by a reference image.
    </div>
    <div class="columns is-centered has-text-centered">
      <img class="info-icon" src="assets/info.svg" />
      <button type="button" class="btn btn-caption btn-sm" disabled>This application uses the&nbsp;</button>
    	<button type="button" class="btn btn-caption btn-sm" data-toggle="tooltip" data-placement="bottom" title="This head is trained contrastively to provide a metric for appearance similarity between two images. As positive examples, we use pairs of frames from a video." disabled>Appearance Similarity Head,&nbsp;</button>
    	<button type="button" class="btn btn-caption btn-sm" data-toggle="tooltip" data-placement="bottom" title="This head is similar to the appearance similarity head, but is instead trained on images of faces." disabled>Identity Head</button>
    </div>
    <br>
    <div class="btn-row">
      <span>identity:<br></span>
      <button type="button" onClick="setActiveButton(this)" class="btn btn-identity btn-select btn-active" btn-identity="man" prompt-key="manIdentity">person 1</button>
      <button type="button" onClick="setActiveButton(this)" class="btn btn-identity btn-select" btn-identity="woman" prompt-key="womanIdentity">person 2</button>
    </div>
    <div class="btn-row">
    <span>prompt:<br></span>
      <button type="button" onClick="setActiveButton(this)" class="btn btn-context btn-select btn-active" btn-context="1">oil painting half body portrait of a man on a city street in copenhagen</button>
      <button type="button" onClick="setActiveButton(this)" class="btn btn-context btn-select" btn-context="2">oil painting of a man</button>
    </div>
    <br>
    <div class="results-grid">
      <div class="results-single">
        <img src="assets/identity/empty.png">
        <video class="layered-video" id="dynamic-identity" autoplay muted playsinline loop>
          <source src="assets/identity/man_1.m4v" type="video/mp4">
        </video>
      </div>
    </div>
  </div>
</section>
<!-- Identity Consistency -->

<!-- Image Variations -->
<hr>
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-4 is-centered has-text-centered">Image Variations</h2>
    <div class="caption">
      With the appearance similarity head, we can explore different amounts of image variation by changing the guidance weight.
    </div>
    <div class="columns is-centered has-text-centered">
      <img class="info-icon" src="assets/info.svg" />
      <button type="button" class="btn btn-caption btn-sm" disabled>This application uses the&nbsp;</button>
    	<button type="button" class="btn btn-caption btn-sm" data-toggle="tooltip" data-placement="bottom" title="This head is trained contrastively to provide a metric for appearance similarity between two images. As positive examples, we use pairs of frames from a video." disabled>Appearance Similarity Head</button>
    </div>
    <br>
    <div class="btn-row">
      <span>prompt:<br></span>
      <button type="button" onClick="setActiveButton(this)" class="btn btn-image-var btn-select btn-active" btn-image-var="dog">a dog is walking down the street</button>
      <button type="button" onClick="setActiveButton(this)" class="btn btn-image-var btn-select" btn-image-var="astronaut">an astronaut is skiing down the hill</button>
    </div>
    <br>
    <div class="results-grid">
      <div class="results-pair">
        <img id="dynamic-image-var-ref" src="assets/image_var/dog_ref.png" />
        <img id="dynamic-image-var" src="assets/image_var/dog_0.png" />
        <div style="width:90%;">
          <b style="font-size:14px;text-align:center;"> RG Weight </b>
          <input id="dynamicSlider" type="range" value="0.0" min="0.0" max="1.0" step = "0.1" oninput="setSlider(this)">
          <b id="dynamicSliderValue">0</b>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- Image Variations -->

<hr>
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title is-4">Acknowledgements</h2>
    <span>
      We would like to thank Stephanie Fu, Eric Wallace, Yossi Gandelsman, Dave Epstein, Ben Poole, 
      Thomas Iljic, Brent Yi, Kevin Black, Jessica Dai, Ethan Weber, Rundi Wu, Xiaojuan Wang, 
      Luming Tang, Ruiqi Gao, Jason Baldridge, Zhengqi Li, and Angjoo Kanazawa for helpful discussions and feedback.
    </span>
    <h2 class="title is-4">BibTeX</h2>
    <pre><code>
    @article{luo2023readoutguidance,
      title={Readout Guidance: Learning Control from Diffusion Features},
      author={Grace Luo and Trevor Darrell and Oliver Wang and Dan B Goldman and Aleksander Holynski},
      journal={arXiv preprint},
      year={2023}
    }
    </code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            The website template is based on the
            <a href="https://nerfies.github.io">Nerfies</a>,
            <a href="https://diffusion-hyperfeatures.github.io">Diffusion Hyperfeatures</a>,
            <a href="https://dreamsim-nights.github.io">DreamSim</a>,
            <a href="https://rl-diffusion.github.io">DDPO</a>,
            and  <a href="https://dave.ml/selfguidance">Self-Guidance</a>
            project pages.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

<script>
  $(function () {
    $('[data-toggle="tooltip"]').tooltip()
  });
</script>
<!-- <script>
  const replay = document.querySelector('.replay');
  replay.addEventListener('click', () => {
      const video = document.getElementById("teaser")
      video.currentTime = 0;
      video.play();
  });
</script> -->
</body>
</html>
